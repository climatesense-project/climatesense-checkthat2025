{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37ff9f",
   "metadata": {},
   "source": [
    "# Class Oversampling\n",
    "\n",
    "Using Deepseek, we generate new examples by paraphrasing the existing text. We use 'personas' for creating different variations.\n",
    "Two approaches are taken:\n",
    "\n",
    "1. For each subclass, we create a new sample. In this context, we will need 3 classifiers rather than a multilabel classifier.\n",
    "2. We create a main zero class and then only expand the subsets.\n",
    "\n",
    "**We do not oversample for the multilabel classifier.**\n",
    "\n",
    "**The generated output needs some manual cleaning.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fea741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import List\n",
    "\n",
    "import ollama\n",
    "\n",
    "PERSONALITIES = [\n",
    "    \"friendly\",\n",
    "    \"formal\",\n",
    "    \"humorous\",\n",
    "    \"poetic\",\n",
    "    \"sarcastic\",\n",
    "    \"dramatic\",\n",
    "    \"scientific\",\n",
    "    \"mysterious\",\n",
    "    \"adventurous\",\n",
    "    \"romantic\",\n",
    "    \"philosophical\",\n",
    "    \"historical\",\n",
    "    \"technical\",\n",
    "    \"casual\",\n",
    "    \"business-like\",\n",
    "    \"playful\",\n",
    "    \"empathetic\",\n",
    "    \"authoritative\",\n",
    "    \"inquisitive\",\n",
    "    \"optimistic\",\n",
    "    \"pessimistic\",\n",
    "    \"cynical\",\n",
    "    \"realistic\",\n",
    "    \"idealistic\",\n",
    "    \"whimsical\",\n",
    "    \"nostalgic\",\n",
    "    \"sophisticated\",\n",
    "    \"down-to-earth\",\n",
    "    \"witty\",\n",
    "    \"charming\",\n",
    "    \"enigmatic\",\n",
    "    \"intellectual\",\n",
    "    \"artistic\",\n",
    "]\n",
    "\n",
    "\n",
    "class OllamaTextOversampler:\n",
    "    def __init__(\n",
    "        self,\n",
    "        api_url: str = \"http://localhost:11434\",\n",
    "        model: str = \"deepseek-r1:7b\",\n",
    "        personalities: List[str] = None,\n",
    "    ) -> str | List[str]:\n",
    "        self.api_url = api_url\n",
    "        self.model = model\n",
    "        self.personalities = personalities\n",
    "\n",
    "    def generate_alternatives(self, text: str, n: int = 1):\n",
    "        output_texts = []\n",
    "        for _ in range(n):\n",
    "            # Randomly select a personality:\n",
    "            if len(self.personalities) > 0:\n",
    "                personality = random.choice(self.personalities)\n",
    "                prompt = f'Just answer with the text and nothing else, generate an alternate version of the following tweet as if you were \"{personality}\": {text}'  # noqa: E501\n",
    "            else:\n",
    "                personality = None\n",
    "                prompt = f'Just answer with the text and nothing else, generate an alternate version of the following tweet: \"{text}\"'  # noqa: E501\n",
    "\n",
    "            # Prepare the request payload\n",
    "            response = ollama.chat(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                options={\n",
    "                    \"temperature\": 0.7,\n",
    "                    \"max_tokens\": 100,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"frequency_penalty\": 0.5,\n",
    "                    \"presence_penalty\": 0.5,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            # Todo add support for custom cleanup method\n",
    "            if \"deepseek\" in self.model:\n",
    "                output_texts.append(response.message.content.split(\"</think>\")[-1].strip())\n",
    "            else:\n",
    "                output_texts.append(response.message.content.strip())\n",
    "\n",
    "        # Return the generated texts:\n",
    "        if len(output_texts) == 1:\n",
    "            return output_texts[0]\n",
    "        else:\n",
    "            return output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd7130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class balance for scientific_claim:\n",
      "{0.0: 0.7296416938110749, 1.0: 0.2703583061889251}\n",
      "\n",
      "Class balance for scientific_reference:\n",
      "{0.0: 0.8175895765472313, 1.0: 0.18241042345276873}\n",
      "\n",
      "Class balance for scientific_entities:\n",
      "{0.0: 0.750814332247557, 1.0: 0.249185667752443}\n"
     ]
    }
   ],
   "source": [
    "# Get class balanace for the following columns: \"scientific_claim\", \"scientific_reference\", \"scientific_entities\":\n",
    "def get_class_balance(df, column):\n",
    "    class_counts = df[column].value_counts()\n",
    "    total_count = len(df)\n",
    "    class_balance = {cls: count / total_count for cls, count in class_counts.items()}\n",
    "    return class_balance\n",
    "\n",
    "\n",
    "def get_class_balance_for_all_columns(df, columns):\n",
    "    class_balances = {}\n",
    "    for column in columns:\n",
    "        class_balances[column] = get_class_balance(df, column)\n",
    "    return class_balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2978893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over-sample the minority classes using the paraphrasing model:\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def oversample_minority_classes(\n",
    "    df: pd.DataFrame,\n",
    "    text_column: str,\n",
    "    class_column: str,\n",
    "    oversampler: OllamaTextOversampler,\n",
    "):\n",
    "    # Get the class counts\n",
    "    class_counts = df[class_column].value_counts()\n",
    "\n",
    "    # Find the minority class\n",
    "    minority_class = class_counts.idxmin()\n",
    "\n",
    "    # Get the rows of the minority class\n",
    "    minority_rows = df[df[class_column] == minority_class]\n",
    "\n",
    "    # Get how many time each row should be oversampled and round it:\n",
    "    oversample_count = round(class_counts.max() // class_counts.min())\n",
    "    n = oversample_count - 1\n",
    "    print(f\"Over-sampling an additional {n} times for the minority class: {minority_class}\")\n",
    "\n",
    "    # Generate new samples for the minority class\n",
    "    new_samples = []\n",
    "    for _, row in tqdm(minority_rows.iterrows(), total=len(minority_rows)):\n",
    "        text = row[text_column]\n",
    "        new_texts = oversampler.generate_alternatives(text, n=n)\n",
    "\n",
    "        if n == 1:\n",
    "            new_samples = new_samples + [new_texts]\n",
    "        else:\n",
    "            new_samples = new_samples + new_texts\n",
    "\n",
    "    return new_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2c1b2c",
   "metadata": {},
   "source": [
    "## Oversampling for Each Sub-class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4952a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trainning data:\n",
    "# Create the dataset:\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "subtask4a_train_df = pd.DataFrame()\n",
    "subtask4a_dev_df = pd.DataFrame()\n",
    "if os.path.isfile(\"./data/processed/task4/subtask_4a/ct_train_clean.tsv\"):\n",
    "    subtask4a_train_df = pd.read_csv(\"./data/processed/task4/subtask_4a/ct_train_clean.tsv\", sep=\"\\t\")\n",
    "    subtask4a_dev_df = pd.read_csv(\"./data/processed/task4/subtask_4a/ct_dev_clean.tsv\", sep=\"\\t\")\n",
    "else:\n",
    "    subtask4a_train_df = pd.read_csv(\"../../data/processed/task4/subtask_4a/ct_train_clean.tsv\", sep=\"\\t\")\n",
    "    subtask4a_dev_df = pd.read_csv(\"../../data/processed/task4/subtask_4a/ct_dev_clean.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65294c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Vivid and shimmering, this sentence exists as if it\\'s woven from ethereal beauty.\"', '\"I\\'m going to test this sentence.\"', '\"WittyWarning: A sentence starter test went wrong.\"']\n"
     ]
    }
   ],
   "source": [
    "oversampler = OllamaTextOversampler(\n",
    "    api_url=\"http://localhost:11434\",\n",
    "    model=\"deepseek-r1:7b\",\n",
    "    personalities=PERSONALITIES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bb2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"scientific_claim\", \"scientific_reference\", \"scientific_entities\"]\n",
    "class_balances = get_class_balance_for_all_columns(subtask4a_train_df, columns)\n",
    "\n",
    "print(\"Class balance for scientific_claim:\")\n",
    "print(class_balances[\"scientific_claim\"])\n",
    "print(\"\\nClass balance for scientific_reference:\")\n",
    "print(class_balances[\"scientific_reference\"])\n",
    "print(\"\\nClass balance for scientific_entities:\")\n",
    "print(class_balances[\"scientific_entities\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab3c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = {}\n",
    "for cl in [\n",
    "    \"scientific_claim\",\n",
    "    \"scientific_reference\",\n",
    "    \"scientific_entities\",\n",
    "]:  # \"scientific_claim\"\n",
    "    if cl not in new_samples:\n",
    "        new_samples[cl] = oversample_minority_classes(\n",
    "            subtask4a_train_df,\n",
    "            text_column=\"text\",\n",
    "            class_column=cl,\n",
    "            oversampler=oversampler,\n",
    "        )\n",
    "\n",
    "        if os.path.isfile(\"./data/processed/task4/subtask_4a/ct_train_clean.tsv\"):\n",
    "            pd.DataFrame({\"text\": new_samples[cl], f\"{cl}\": 1.0}).to_csv(\n",
    "                f\"./data/processed/task4/subtask_4a/ct_train_oversamples_{cl}.tsv\",\n",
    "                sep=\"\\t\",\n",
    "                index=False,\n",
    "                header=False,\n",
    "            )\n",
    "        else:\n",
    "            pd.DataFrame({\"text\": new_samples[cl], f\"{cl}\": 1.0}).to_csv(\n",
    "                f\"../../data/processed/task4/subtask_4a/ct_train_oversamples_{cl}.tsv\",\n",
    "                sep=\"\\t\",\n",
    "                index=False,\n",
    "                header=False,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f8dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the new samples as tsv files:\n",
    "import os\n",
    "\n",
    "for cl in new_samples.keys():\n",
    "    if os.path.isfile(\"./data/processed/task4/subtask_4a/ct_train_clean.tsv\"):\n",
    "        pd.DataFrame({\"text\": new_samples[cl], f\"{cl}\": 1.0}).to_csv(\n",
    "            f\"./data/processed/task4/subtask_4a/ct_train_oversamples_{cl}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index=False,\n",
    "            header=False,\n",
    "        )\n",
    "    else:\n",
    "        pd.DataFrame({\"text\": new_samples[cl], f\"{cl}\": 1.0}).to_csv(\n",
    "            f\"../../data/processed/task4/subtask_4a/ct_train_oversamples_{cl}.tsv\",\n",
    "            sep=\"\\t\",\n",
    "            index=False,\n",
    "            header=False,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatesense-checkthat2025-task4-F-tagyMC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
